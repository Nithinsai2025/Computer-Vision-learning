{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f516c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"Nithinsai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45eabe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a32998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Access first coloumn\n",
    "tensor=torch.tensor([[10,20,30],[40,50,60],[70,80,90]])\n",
    "print(tensor.ndim)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a210bb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20, 30],\n",
       "        [40, 50, 60],\n",
       "        [70, 80, 90]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same like numpy accessing\n",
    "tensor[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1a430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20, 30],\n",
       "        [40, 50, 60]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slicing operations\n",
    "tensor[:2,:] #First two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3608d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 20],\n",
      "        [40, 50],\n",
      "        [70, 80]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59785c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50, 60],\n",
       "        [80, 90]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1:3,1:3] # slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d8c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 90])\n"
     ]
    }
   ],
   "source": [
    "# Fancy indexing\n",
    "#(0,1)-->20\n",
    "#(2,2)-->90\n",
    "selecting_elements=tensor[[0,2],[1,2]]\n",
    "print(selecting_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1237a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50, 60, 70, 80, 90])\n"
     ]
    }
   ],
   "source": [
    "# boolean indexing\n",
    "mask=tensor>=50\n",
    "print(tensor[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bfe202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing or mutable via indexing\n",
    "\n",
    "tensor[0,1]=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a513e220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 25],\n",
       "        [40, 50],\n",
       "        [70, 80]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_copy=tensor[:3,:2]\n",
    "tensor_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0709a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 15],\n",
       "        [40, 50],\n",
       "        [70, 80]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_copy[0,1]=15\n",
    "tensor_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdc20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[:,0]=torch.tensor([100,400,700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3807d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100,  15,  30],\n",
       "        [400,  50,  60],\n",
       "        [700,  80,  90]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f3da6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,  15,  30],\n",
      "        [700,  80,  90]])\n"
     ]
    }
   ],
   "source": [
    "indices=torch.tensor([0,2])\n",
    "selected_rows=torch.index_select(tensor,dim=0,index=indices) # dim=0 only rows\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bfad13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 30,  15, 100],\n",
      "        [ 60,  50, 400],\n",
      "        [ 90,  80, 700]])\n",
      "tensor([[700,  80,  90],\n",
      "        [400,  50,  60],\n",
      "        [100,  15,  30]])\n"
     ]
    }
   ],
   "source": [
    "# reversing using flip\n",
    "#print(tensor[::-1])\n",
    "print(torch.flip(tensor,dims=(1,)))\n",
    "print(torch.flip(tensor,dims=(0,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196cd070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0420, 0.0405, 0.3211, 0.8076, 0.3586, 0.3718, 0.0604, 0.9860, 0.8777,\n",
       "        0.5184])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random numbers\n",
    "random_tensor=torch.rand(10) # provides 10 random numbers between 0-1\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0255c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0176, 0.3443, 0.3228],\n",
      "         [0.4638, 0.0169, 0.7578],\n",
      "         [0.0151, 0.0665, 0.0283],\n",
      "         [0.3324, 0.3382, 0.3764],\n",
      "         [0.9195, 0.6889, 0.2720]],\n",
      "\n",
      "        [[0.9548, 0.6986, 0.7602],\n",
      "         [0.8240, 0.8217, 0.3114],\n",
      "         [0.3619, 0.0589, 0.0043],\n",
      "         [0.8827, 0.5579, 0.6894],\n",
      "         [0.0687, 0.2231, 0.3609]]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor=torch.rand(2,5,3) # 2 of (5,3) matrix\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49263e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566, 0.7936, 0.9408,\n",
       "        0.1332])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random_tensor=torch.rand(10) # seed is given\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a428954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 5, 9],\n",
      "        [1, 1, 5],\n",
      "        [3, 5, 4],\n",
      "        [5, 5, 9],\n",
      "        [2, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Generate Normal Integers\n",
    "print(torch.randint(1,10,(5,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "614c0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.4979,  3.2328,  3.5862,  1.8274, -0.1420])\n"
     ]
    }
   ],
   "source": [
    "# Generate random numbers from normal distributions\n",
    "\n",
    "# torch.normal(mean,std,size)\n",
    "random_normal=torch.normal(1,2,(5,))\n",
    "print(random_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c7184",
   "metadata": {},
   "source": [
    "## Creating Noise image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5562dcee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#h,w of image 256x256\u001b[39;00m\n\u001b[32m      5\u001b[39m uniform_noise=torch.rand(\u001b[32m256\u001b[39m,\u001b[32m256\u001b[39m) \u001b[38;5;66;03m# between 0-1\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#h,w of image 256x256\n",
    "\n",
    "uniform_noise=torch.rand(256,256) # between 0-1\n",
    "plt.imshow(uniform_noise.numpy(),cmap='grey')\n",
    "plt.title(\"Uniform noise image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82db327d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m uniform_noise_rgb=torch.rand(\u001b[32m256\u001b[39m,\u001b[32m256\u001b[39m,\u001b[32m3\u001b[39m) \u001b[38;5;66;03m# between 0-1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m.imshow(uniform_noise_rgb.numpy())\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mUniform noise image RGB\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "uniform_noise_rgb=torch.rand(256,256,3) # between 0-1\n",
    "plt.imshow(uniform_noise_rgb.numpy())\n",
    "plt.title(\"Uniform noise image RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4a65727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9040, 0.5547, 0.3423],\n",
      "         [0.6343, 0.3644, 0.7104],\n",
      "         [0.9464, 0.7890, 0.2814],\n",
      "         ...,\n",
      "         [0.2230, 0.4166, 0.1630],\n",
      "         [0.9885, 0.3997, 0.6986],\n",
      "         [0.0535, 0.7878, 0.3446]],\n",
      "\n",
      "        [[0.1197, 0.5731, 0.7422],\n",
      "         [0.9327, 0.1946, 0.2539],\n",
      "         [0.5961, 0.6356, 0.6922],\n",
      "         ...,\n",
      "         [0.4606, 0.3515, 0.4982],\n",
      "         [0.6605, 0.4890, 0.5231],\n",
      "         [0.5633, 0.6862, 0.3483]],\n",
      "\n",
      "        [[0.2019, 0.6180, 0.4408],\n",
      "         [0.2735, 0.7100, 0.5045],\n",
      "         [0.4273, 0.2580, 0.4342],\n",
      "         ...,\n",
      "         [0.0263, 0.6988, 0.9117],\n",
      "         [0.2242, 0.6348, 0.4420],\n",
      "         [0.4818, 0.5291, 0.9333]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4553, 0.9983, 0.9154],\n",
      "         [0.7205, 0.0675, 0.9463],\n",
      "         [0.3992, 0.5067, 0.7542],\n",
      "         ...,\n",
      "         [0.7451, 0.2902, 0.4987],\n",
      "         [0.0369, 0.5494, 0.4745],\n",
      "         [0.6425, 0.4817, 0.8017]],\n",
      "\n",
      "        [[0.0119, 0.1018, 0.5591],\n",
      "         [0.1722, 0.3210, 0.9809],\n",
      "         [0.3672, 0.2890, 0.2611],\n",
      "         ...,\n",
      "         [0.3483, 0.7266, 0.7688],\n",
      "         [0.7931, 0.2488, 0.2230],\n",
      "         [0.5215, 0.4925, 0.9767]],\n",
      "\n",
      "        [[0.1614, 0.6202, 0.9448],\n",
      "         [0.1399, 0.0209, 0.2421],\n",
      "         [0.2960, 0.7868, 0.7678],\n",
      "         ...,\n",
      "         [0.5104, 0.6464, 0.0048],\n",
      "         [0.0766, 0.0784, 0.7672],\n",
      "         [0.1566, 0.4489, 0.3373]]])\n"
     ]
    }
   ],
   "source": [
    "print(uniform_noise_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a35b3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# zeros and ones\n",
    "zeros_tensor=torch.zeros(3,3,3)\n",
    "print(zeros_tensor)\n",
    "print(zeros_tensor.shape)\n",
    "ones_tensor=torch.ones(3,3,3)\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990c8694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*float--for most deep learning task-->float32,float64,float16\\n*integers- for categorical data and indices-->int32,int64,int8\\n*Booleans-mask or logical operations\\n*Complex number- advanced computation-->complex64,complex128\\n\\n*float16 is computationally efficient but precision is less\\n*float64 is more accurate but computationally heavy\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Types for tensors\n",
    "\"\"\"\n",
    "*float--for most deep learning task-->float32,float64,float16\n",
    "*integers- for categorical data and indices-->int32,int64,int8\n",
    "*Booleans-mask or logical operations\n",
    "*Complex number- advanced computation-->complex64,complex128\n",
    "\n",
    "*float16 is computationally efficient but precision is less\n",
    "*float64 is more accurate but computationally heavy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed2359ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 2.5000, 3.5000], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=torch.tensor([1.5,2.5,3.5])\n",
    "d.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9288ecfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.tensor([True,False,True,False])\n",
    "b.to(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dd0e1",
   "metadata": {},
   "source": [
    "## Impact of datatype on memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0da2503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory used by float32: 4000 bytes\n",
      "memory used by float32: 8000 bytes\n"
     ]
    }
   ],
   "source": [
    "float_32=torch.ones(1000,dtype=torch.float32)\n",
    "float_64=torch.ones(1000,dtype=torch.float64)\n",
    "\n",
    "#Tensor.element_size()-size of one element\n",
    "# element_size()--> gives you size of one element in bytes\n",
    "\n",
    "print(\"memory used by float32:\",float_32.element_size()*float_32.nelement(),'bytes')\n",
    "print(\"memory used by float32:\",float_64.element_size()*float_64.nelement(),'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#float32--> default for most NN models\n",
    "#float64--> high precision computation\n",
    "#int32--> general purpose integer\n",
    "#int64--> tensor indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec56e9",
   "metadata": {},
   "source": [
    "## Tensor Manipulation\n",
    "\n",
    "-Reshaping\n",
    "\n",
    "-slicing\n",
    "\n",
    "-joining or splitting\n",
    "\n",
    "-transposing and permuting dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945d0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping tensors\n",
    "#reshape and view\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f907d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tensor=torch.arange(0,12,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aaba56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1043912",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m secondary_t=torch.arange(\u001b[32m12\u001b[39m,\u001b[32m24\u001b[39m,dtype=torch.float32)\n\u001b[32m      2\u001b[39m secondary_t.reshape(\u001b[32m4\u001b[39m,\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecondary_t\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "secondary_t=torch.arange(12,24,dtype=torch.float32)\n",
    "secondary_t.reshape(4,3)\n",
    "torch.transpose(secondary_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c9777f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m original_tensor.matmul(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecondary_t\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "original_tensor.matmul(torch.transpose(secondary_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6239f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d27a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    }
   ],
   "source": [
    "#view\n",
    "print(original_tensor.is_contiguous())\n",
    "flattened=original_tensor.view(-1)\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb00a0",
   "metadata": {},
   "source": [
    "## Joining Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950fb00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat()--> Merges tensors along existing dimensions\n",
    "first=torch.tensor([[1,2],[3,4]])\n",
    "second=torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "con_rows=torch.cat((first,second),dim=0)\n",
    "con_cols=torch.cat((first,second),dim=1)\n",
    "print(con_rows)\n",
    "print(con_cols)\n",
    "print(con_rows.shape)\n",
    "print(con_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2add0fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "tensor([[[1, 2],\n",
      "         [5, 6]],\n",
      "\n",
      "        [[3, 4],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# stack --> created a new dimension increases the tensor's rank\n",
    "\n",
    "stack_rows=torch.stack((first,second),dim=0)\n",
    "stack_cols=torch.stack((first,second),dim=1)\n",
    "print(stack_rows.shape)\n",
    "print(stack_cols.shape)\n",
    "print(stack_rows)\n",
    "print(stack_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a413c",
   "metadata": {},
   "source": [
    "## Splitting tensors\n",
    "\n",
    "torch.chunk()-->divides tensor into equal sized chunk\n",
    "\n",
    "torch.split()-->allows uneven splitting as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5372c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]), tensor([ 8,  9, 10, 11]))\n"
     ]
    }
   ],
   "source": [
    "# torch.chunk\n",
    "tensor=torch.arange(12)\n",
    "chunk=torch.chunk(tensor,3,dim=0)\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21671e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
